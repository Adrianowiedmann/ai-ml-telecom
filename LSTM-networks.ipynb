{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Nome: Adriano Ulrich do Prado Wiedmann\n",
        "---\n",
        "\n",
        "Matrícula: 202014824"
      ],
      "metadata": {
        "id": "ByFc0CSxEbHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#allows the drive to be accessed\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShokAOQcoMy2",
        "outputId": "71e61209-23ba-4dbc-9615-66a31e226edb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# used for manipulating directory paths\n",
        "import os\n",
        "\n",
        "# Scientific and vector computation for python\n",
        "import numpy as np\n",
        "\n",
        "# Plotting library\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# tells matplotlib to embed plots within the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "\n",
        "# modules to adequate the NN\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# modules to process strings\n",
        "from string import punctuation\n",
        "\n",
        "# module to organize the words\n",
        "from collections import Counter\n",
        "\n",
        "# Measuring execution time\n",
        "import time\n"
      ],
      "metadata": {
        "id": "Ysj2hfm0ofmZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testar_gpu():\n",
        "\ttrain_on_gpu = torch.cuda.is_available() #Observa se a GPU está disponivel\n",
        "\tif train_on_gpu: #Se sim\n",
        "\t\tdevice = torch.device('cuda') #Seleciona o device como GPU\n",
        "\t\tprint(\"Treinando na GPU\") #E manda a mensagem\n",
        "\telse: #Se não\n",
        "\t\tdevice = torch.device('cpu') #Seleciona o device como cpu\n",
        "\t\tprint(\"GPU indisponível, treinando na CPU\") #E avisa que a GPU não esta disponível\n",
        "\treturn device\n",
        "\n",
        "device = testar_gpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE6V82gNoqDS",
        "outputId": "745a61aa-5f9b-4b7f-d42a-41c839af1179"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinando na GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read data from text files\n",
        "with open('/content/drive/MyDrive/DP6/data/reviews.txt', 'r') as f:\n",
        "    reviews = f.read()\n",
        "with open('/content/drive/MyDrive/DP6/data/labels.txt', 'r') as f:\n",
        "    labels = f.read()"
      ],
      "metadata": {
        "id": "ctKUuesHoruI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reviews[:1000])\n",
        "print()\n",
        "print(labels[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W60W7a0Uotxn",
        "outputId": "2d930d54-d76e-4eda-e3c3-e922abd2dee0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \n",
            "story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turn\n",
            "\n",
            "positive\n",
            "negative\n",
            "po\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get rid of punctuation\n",
        "reviews = reviews.lower() # lowercase, standardize\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])"
      ],
      "metadata": {
        "id": "WcXEDiOfou7A"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split by new lines and spaces\n",
        "reviews_split = all_text.split('\\n')\n",
        "\n",
        "print(f'O número de reviews presentes no dataset é:{len(reviews_split)}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPhvoUnPoxJ9",
        "outputId": "e3e425a4-4c56-408c-d3b9-2d4a7f08aef3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O número de reviews presentes no dataset é:25001.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_text = ' '.join(reviews_split)\n",
        "\n",
        "# create a list of words\n",
        "words = all_text.split()\n",
        "\n",
        "print(f'O número de palavras presentes no dataset é:{len(words)}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wunB1DuoyN7",
        "outputId": "edc3d1b7-19c9-4791-a37d-0b02a623ae03"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O número de palavras presentes no dataset é:6020196.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Build a dictionary that maps words to integers\n",
        "counts = Counter(words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}"
      ],
      "metadata": {
        "id": "sthaxNrcozLr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## use the dict to tokenize each review in reviews_split\n",
        "## store the tokenized reviews in reviews_ints\n",
        "reviews_ints = []\n",
        "for review in reviews_split:\n",
        "    reviews_ints.append([vocab_to_int[word] for word in review.split()])"
      ],
      "metadata": {
        "id": "zJc7dmopo0iq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1=positive, 0=negative label conversion\n",
        "labels_split = labels.split('\\n')\n",
        "encoded_labels = np.array([1 if label == 'positive' else 0 for label in labels_split])"
      ],
      "metadata": {
        "id": "xY08LSgko2b7"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier review stats\n",
        "review_lens = Counter([len(x) for x in reviews_ints])\n",
        "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
        "print(\"Maximum review length: {}\".format(max(review_lens)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lN7sBmWo3Za",
        "outputId": "867ee9ee-5191-40f2-f98c-94e7ac3ce9dd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-length reviews: 1\n",
            "Maximum review length: 2514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
        "\n",
        "## remove any reviews/labels with zero length from the reviews_ints list.\n",
        "\n",
        "# get indices of any reviews with length 0\n",
        "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
        "\n",
        "# remove 0-length reviews and their labels\n",
        "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
        "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
        "\n",
        "print('Number of reviews after removing outliers: ', len(reviews_ints))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDNx_Ripo4Zk",
        "outputId": "81aec559-2be2-4aa0-cd2c-6600cf3d5cd6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews before removing outliers:  25001\n",
            "Number of reviews after removing outliers:  25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_features(reviews_ints, seq_length):\n",
        "    \"\"\"\n",
        "    Retorna os features de 'review_ints', em que cada review é preenchida com\n",
        "    zeros ou truncada no tamanho determinado pela entrada 'seq_length'.\n",
        "\n",
        "    Parâmetros\n",
        "    ----------\n",
        "    reviews_ints: list\n",
        "      Lista que contém todas as avaliações (mapeadas em números inteiros), uma\n",
        "      em cada elemento da lista.\n",
        "\n",
        "    seq_length: int\n",
        "      Valor que será usado como tamanho padrão de cada linha da matriz\n",
        "      'features'.\n",
        "\n",
        "    Retorna\n",
        "    --------\n",
        "    features: np.array\n",
        "      Matriz que contém na linha 'i' o vetor de features do exemplo 'i'. O\n",
        "      número de colunas é igual a 'seq_length'.\n",
        "\n",
        "    Instruções\n",
        "    ------------\n",
        "    Para cada vetor contido em 'reviews_ints', adicione zeros caso o tamanho\n",
        "    do vetor seja menor que 'seq_length' ou trunque o vetor em 'seq_length'\n",
        "    caso o tamanho do vetor seja maior.\n",
        "    \"\"\"\n",
        "\n",
        "    # getting the correct rows x cols shape\n",
        "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
        "\n",
        "    # for each review, I grab that review and\n",
        "    for i, row in enumerate(reviews_ints):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "DrBzguU5o5Qz"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 200\n",
        "\n",
        "features = pad_features(reviews_ints, seq_length=seq_length)\n",
        "\n",
        "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
        "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
        "\n",
        "print(features[:30,:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwMW90Fvo6FS",
        "outputId": "dc7ed718-c577-4579-c547-173b9191bed3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [22382    42 46418    15   706 17139  3389    47    77    35]\n",
            " [ 4505   505    15     3  3342   162  8312  1652     6  4819]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [   54    10    14   116    60   798   552    71   364     5]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    1   330   578    34     3   162   748  2731     9   325]\n",
            " [    9    11 10171  5305  1946   689   444    22   280   673]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    1   307 10399  2069  1565  6202  6528  3288 17946 10628]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [   21   122  2069  1565   515  8181    88     6  1325  1182]\n",
            " [    1    20     6    76    40     6    58    81    95     5]\n",
            " [   54    10    84   329 26230 46427    63    10    14   614]\n",
            " [   11    20     6    30  1436 32317  3769   690 15100     6]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [   40    26   109 17952  1422     9     1   327     4   125]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [   10   499     1   307 10399    55    74     8    13    30]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_frac = 0.85\n",
        "\n",
        "## split data into training and test data (features and labels, x and y)\n",
        "split_idx = int(len(features)*split_frac)\n",
        "train_x, test_x = features[:split_idx], features[split_idx:]\n",
        "train_y, test_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
        "\n",
        "## print out the shapes of your resultant feature data\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB2Ppncro712",
        "outputId": "2c9424cb-9561-4073-8f04-7d651903d66e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(21250, 200) \n",
            "Test set: \t\t(3750, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# make sure the SHUFFLE your training data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "aBWl14e0o9Lk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter)\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiXzbIAjo-OT",
        "outputId": "ec868a16-84e8-4cde-f8bd-338ee7d44924"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([50, 200])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Classe referente ao modelo que será usado para realizar a análise de\n",
        "    sentimento.\n",
        "\n",
        "    Instruções\n",
        "    ------------\n",
        "    Defina as camadas da rede conforme a arquitetura pedida (camada de\n",
        "    embedding, camada LSTM e camada fully connected com sigmoid no fim).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "\n",
        "        # Initialize the model by setting up the layers.\n",
        "\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # ============================== YOUR CODE HERE ================================\n",
        "        # Camada de embedding:\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Camada LSTM:\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers,\n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "\n",
        "        # Camada dropout\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        # Camada fully connected:\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "        # camada Sigmoid\n",
        "        self.sig = nn.Sigmoid()\n",
        "        # ==============================================================================\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        # embeddings and lstm_out\n",
        "        x = x.long()\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        lstm_out = lstm_out[:, -1, :] # getting the last time step output\n",
        "\n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
        "\n",
        "        return hidden\n"
      ],
      "metadata": {
        "id": "n5coYE8jo_rz"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "model = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers).to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iFrBM_5pA6F",
        "outputId": "c55d40bb-3a2a-4690-96c8-6f9c70e9c5c5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(74073, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.001\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "clip = 5"
      ],
      "metadata": {
        "id": "9IsGj9txpCNE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Treine os parâmetros das camadas de embedding e LSTM da rede contida em\n",
        "'model' com os exemplos contidos em 'data_train' (organizados por\n",
        "'train_loader'). Em seguida, teste a acurácia e o erro de classificação da\n",
        "rede com os exemplos contidos em 'data_test' (organizados por\n",
        "'loader_test').\n",
        "\n",
        "Instruções\n",
        "-------------\n",
        "Efetue o treinamento e testa da rede, realizando uma passagem dos datasets\n",
        "de treino e de teste a cada época, calculando o erro de classificação de\n",
        "cada 'batch' e atualizando os parâmetros da rede com o otimizador definido\n",
        "anteriormente, e então calcule o erro médio de classificação pela rede dos\n",
        "exemplos de treino (guardando o resultado em 'train_loss'), o error médio\n",
        "de classificação pela rede dos exemplos de teste (guardando o resultado em\n",
        "'test_loss') e a acurácia de classificação pela rede dos exemplos de teste\n",
        "(guardando o resultado em 'acc').\n",
        "Nota\n",
        "-------------\n",
        "O aluno pode fazer uso de quaisquer ferramentas fornecidas pelo Pytorch\n",
        "para implementar esta função.\n",
        "\n",
        "É importante lembrar de utilizar a GPU para efetuar quaisquer processamentos\n",
        "possíveis (utilize a função 'to(device)') a fim de otimizar o tempo de\n",
        "execução.\n",
        "\"\"\"\n",
        "\n",
        "START = time.time()\n",
        "\n",
        "list_train_loss = []\n",
        "list_test_loss = []\n",
        "list_acc = []\n",
        "time1epoch = 0\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss, test_loss, acc = 0,0,0\n",
        "\n",
        "  # ============================== YOUR CODE HERE ================================\n",
        "  model.train()\n",
        "  hidden = model.init_hidden(batch_size)\n",
        "  loss = 0\n",
        "  for inputs_treino, labels_treino in train_loader:\n",
        "    inputs_treino, labels_treino = inputs_treino.to(device), labels_treino.to(device)\n",
        "    hidden = tuple([each.data for each in hidden])\n",
        "    model.zero_grad()\n",
        "    output, hidden = model(inputs_treino, hidden)\n",
        "    test_loss = criterion(output.squeeze(), labels_treino.float())\n",
        "    test_loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), clip).to(device)\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss += test_loss.item()\n",
        "  model.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  test_loss = 0\n",
        "  hidden = model.init_hidden(batch_size)\n",
        "  for inputs_teste, labels_teste in test_loader:\n",
        "    inputs_teste, labels_teste = inputs_teste.to(device), labels_teste.to(device)\n",
        "    output, hidden = model(inputs_teste, hidden)\n",
        "    test_loss += criterion(output.squeeze(), labels_teste.float())\n",
        "    pred = torch.round(output.squeeze())\n",
        "    correct += (pred == labels_teste).sum().item()\n",
        "    total += batch_size\n",
        "\n",
        "  test_loss = test_loss/batch_size\n",
        "  acc = (correct/total)*100\n",
        "\n",
        "\n",
        " \t# ==============================================================================\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "  list_train_loss.append(train_loss), list_test_loss.append(test_loss), list_acc.append(acc)\n",
        "\n",
        "  Time = end - start\n",
        "  if epoch == 1:\n",
        "    time1epoch = Time\n",
        "\n",
        "  print('Epoch: ', epoch ,' loss: {:.4f}'.format(test_loss.item()), ' Accuracy: {:.2f}'.format(acc), ' Time spent this epoch: {:.2f}'.format(Time), 'seconds.')\n",
        "\n",
        "END = time.time()\n",
        "\n",
        "print()\n",
        "TIME = (END - START) - time1epoch\n",
        "print('\\n Time spent during training, excluding first epoch: {:.2f}'.format(TIME), 'seconds.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laR1TkJ8pDsp",
        "outputId": "be56a4e6-3ede-43b8-e748-9250720dad24"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1  loss: 0.7974  Accuracy: 73.95  Time spent this epoch: 22.71 seconds.\n",
            "Epoch:  2  loss: 0.6629  Accuracy: 78.13  Time spent this epoch: 22.56 seconds.\n",
            "Epoch:  3  loss: 0.6722  Accuracy: 81.28  Time spent this epoch: 22.13 seconds.\n",
            "Epoch:  4  loss: 0.7510  Accuracy: 80.96  Time spent this epoch: 22.41 seconds.\n",
            "Epoch:  5  loss: 0.8863  Accuracy: 81.17  Time spent this epoch: 22.53 seconds.\n",
            "\n",
            "\n",
            " Time spent during training, excluding first epoch: 89.64 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_processing(test_review):\n",
        "\n",
        "    \"\"\"\n",
        "    Pré-processa a string de entrada 'test_review' de forma a adequá-la como\n",
        "    parâmetro de entrada para a rede.\n",
        "\n",
        "    Parâmetros\n",
        "    ----------\n",
        "    test_review: str\n",
        "      String referente ao comentário que se deseja analisar o sentimento pela\n",
        "      rede neural.\n",
        "\n",
        "    Retorna\n",
        "    --------\n",
        "    features: torch.tensor\n",
        "      Tensor que contém na linha o vetor de features do exemplo em questão. O\n",
        "      tamanho do tensor é igual a 'seq_length'.\n",
        "\n",
        "    Instruções\n",
        "    ------------\n",
        "    Realize as mesmas operações que foram feitas com o dataset de treino: i)\n",
        "    colocar todo o texto em letras minúsculas; ii) excluir pontuação; iii)\n",
        "    troque as palavras por índices do dicionário 'vocab_to_int'; iv) trunque\n",
        "    ou adicione zeros ao vetor para que seu tamanho seja igual a 'seq_length'\n",
        "    (pode ser feito chamando a função pad_features); e v) passe o tensor para a\n",
        "    GPU ('x.to(device)').\n",
        "    \"\"\"\n",
        "\n",
        "  # ============================== YOUR CODE HERE ================================\n",
        "    test_review = test_review.lower()\n",
        "    all_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "\n",
        "    feature_tensor = [vocab_to_int.get(word, 0) for word in all_text.split()]\n",
        "    feature_tensor = pad_features([feature_tensor], seq_length=seq_length)\n",
        "    feature_tensor = torch.tensor(feature_tensor)\n",
        "\n",
        "    #feature_tensor = feature_tensor.cpu()\n",
        "    #feature_tensor = feature_tensor.to(device)\n",
        " \t# ==============================================================================\n",
        "\n",
        "    return feature_tensor\n",
        "\n",
        "# test code and generate tokenized review\n",
        "test_review_neg = 'The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.'\n",
        "feature_tensor = pre_processing(test_review_neg)\n",
        "print(feature_tensor.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jHckg-iph8J",
        "outputId": "8e46cd59-979b-458a-944f-a8e0a25efd7a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(test_review):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    \"\"\"\n",
        "    Recebe uma string que será pré-processada e então analisada pela rede\n",
        "    neural. Com base no valor de saída da rede, define um limiar de\n",
        "    confiabilidade da predição, classificando o comentário como \"Positivo\",\n",
        "    \"Negativo\" ou \"Inconclusivo\".\n",
        "\n",
        "    Parâmetros\n",
        "    ----------\n",
        "    test_review: str\n",
        "      String referente ao comentário que se deseja analisar o sentimento pela\n",
        "      rede neural.\n",
        "\n",
        "    Instruções\n",
        "    ------------\n",
        "    Pré-processe a string 'test_review', chamando a função 'pre_processing()', e\n",
        "    então passe o vetor pré-processado como entrada à rede neural. Analise o\n",
        "    valor de saída da rede e printe na tela \"Positivo\", \"Negativo\" ou\n",
        "    \"Inconclusivo\" com base nos limiares definidos.\n",
        "    \"\"\"\n",
        "\n",
        "    # ============================== YOUR CODE HERE ================================\n",
        "    processed_review = pre_processing(test_review) # String pré-processada\n",
        "    features = pad_features(processed_review, seq_length=seq_length)\n",
        "\n",
        "    batch_size = processed_review.size(0)\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "    model.embedding.weight.data = model.embedding.weight.data.to(device)\n",
        "\n",
        "    processed_review = processed_review.to(device)\n",
        "    output, hidden = model(processed_review, hidden)\n",
        "\n",
        "    # Predição binária\n",
        "    pred = torch.round(output.squeeze())\n",
        "\n",
        "    output = output.item()\n",
        "    if output <= 0.25:\n",
        "      print(\"Negativo\")\n",
        "    elif output >= 0.75:\n",
        "      print(\"Positivo\")\n",
        "    else:\n",
        "      print(\"Inconclusivo\")\n",
        " \t  # ==============================================================================\n"
      ],
      "metadata": {
        "id": "S354NN2zp3jl"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# negative test review\n",
        "test_review_neg = 'The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.'\n",
        "predict(test_review_neg)\n",
        "print()\n",
        "\n",
        "# positive test review\n",
        "test_review_pos = 'This movie had the best acting and the dialogue was so good. I loved it.'\n",
        "predict(test_review_pos)\n",
        "print()\n",
        "\n",
        "# uncorrelated sentence\n",
        "test_review_uncorrelated = 'Curso TopEng - 2/2023.'\n",
        "predict(test_review_uncorrelated)\n",
        "print()\n",
        "\n",
        "# review in another language\n",
        "test_review_another_lenguage = 'O filme é incrível. O melhor filme que já assisti.'\n",
        "predict(test_review_another_lenguage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9IW5wtBqQDh",
        "outputId": "ad8825d4-7c19-4fb9-e5ac-f15cf3bba3ac"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negativo\n",
            "\n",
            "Positivo\n",
            "\n",
            "Inconclusivo\n",
            "\n",
            "Inconclusivo\n"
          ]
        }
      ]
    }
  ]
}